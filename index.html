<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evaluation Metrics</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Evaluation metrics for deep learning
            methods for 3D facial animation synthesis</h1>
        <p>Alkiviadis Pavlou, Kazi Injamamul Haque, Zerrin Yumak</p>
        <p>Utrecht University</p>
    </header>

    <section id="abstract">
        <h3>Abstract</h3>
        <p>The recent advancements in the research field of Audio-Driven Facial Animations have pro-
            vided both new state-of-the-art approaches and more topics to be discovered in depth. One of
            the main factors of any new method is the ability to evaluate its achievements accurately and
            representatively. In Audio-Driven Facial Animations, this is achieved using evaluation metrics
            that either objectively or subjectively compare state-of-the-art models. As expected from an
            early-stage research field, the evaluation section has been following the typical path focusing
            on simple metrics in most cases. This study aims to clarify the process for future researchers
            through an in-depth analysis of evaluation metrics. Another important aspect of this study is
            the understanding of the different approaches deterministic and non-deterministic models need
            in terms of the evaluation of the results. Apprehending the nature of facial animations will also
            be examined by exploring ground truth datasets in various ways</p>
    </section>

    <section id="methodology">
        <h3>Methodology - Nature of Facial Animations</h3>
        <p>
            Multiple state-of-the-art datasets are tested using their Ground Truth dataset aiming to analyse the non-determinism that exists in subjects and emotion categories.
            Using dimensionality reduction techniques such as t-SNE and PCA we evaluated the correlation between same-subject and same-emotion sequences that are performed in datasets such as BIWI, Multiface, 3DMEAD and BEAT.
            During this process, the results proved the existence of non-determinism across sequences that are performed by the same actor with correlation existing between them.
            Multiple different experiments were used to analyse the results concluding to the nature of Facial Animations.
        </p>

        <h3>Methodology - Metrics Inventory</h3>
        <p>
            The study collected the most insightful evaluation metrics existing for 3D Facial Animations and tested them on trained state-of-the-art models providing a clear overview of the results for each metric.
            FaceXHuBERT, FaceFormer, FaceDiffuser, CodeTalker, CodeTalker-ND and ProbTalk3D were all locally trained on BIWI, Multiface and 3DMEAD aiming to provide transparent results for better evaluation of the metrics that were used.
            For each of the models on each dataset, we calculated the objective metrics: LVE, FDD, MVE, Diversity, MEE and CE and also conducted a Perception Study to calculate the Subjective Metrics of Realism and Lip-Sync.
            An in-depth analysis of the results was conducted aiming to identify the pros and cons of each metric alongside the variables that affect them.
        </p>
    </section>

    <section id="bibtex">
        <h3>BibTeX</h3>
        <pre>
     later
        </pre>
    </section>

    <footer>
        <p>This website is licensed under a <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>
        <p>Website based on the Nerfies project page. If you want to reuse their source code, please credit them appropriately.</p>
    </footer>
</body>
</html>
